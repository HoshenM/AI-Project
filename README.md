# Introduction to Artificial Intelligence â€“ Final Project  
**Stroke Prediction using AI & Machine Learning**

This project applies **exploratory data analysis (EDA)**, **data preprocessing**, and both **supervised** and **ensemble learning methods** to a healthcare dataset from Kaggle: [Stroke Diagnosis and Health Metrics Data](https://www.kaggle.com/datasets/shriyashjagtap/stroke-diagnosis-and-health-metrics-data).

It explores **risk factors for stroke** through feature analysis, evaluates **14 machine learning models** with cross-validation and hyperparameter tuning, and validates findings with **statistical significance tests**.  

All outputs are exported as **publication-ready figures and reports** into the `results/` and `figures/` directories.

---

## Project Structure
```
ai_stroke_project/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ preprocessing.py
â”‚ â”œâ”€â”€ eda_analysis.py
â”‚ â”œâ”€â”€ model_training.py
â”‚ â”œâ”€â”€ evaluation.py
â”‚ â”œâ”€â”€ ensemble_methods.py
â”‚ â”œâ”€â”€ pdf_saver.py
â”‚ â””â”€â”€ init.py
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ AI_Project.ipynb # main notebook
â”œâ”€â”€ data/
â”‚ â””â”€â”€ stroke_data.csv # dataset (place here)
â”œâ”€â”€ figures/ # auto-generated figures
â”‚ â”œâ”€â”€ fig1.pdf # feature distributions (EDA)
â”‚ â”œâ”€â”€ fig2.pdf # correlation heatmap
â”‚ â”œâ”€â”€ fig3.pdf # model comparison & selection
â”‚ â”œâ”€â”€ fig4.pdf # ROC curves, PR curves, confusion matrices
â”‚ â””â”€â”€ fig5.pdf # ensemble results & statistical tests
â”œâ”€â”€ results/
â”‚ â””â”€â”€ final_report.pdf # exported report
â”œâ”€â”€ main.py # orchestrates full pipeline
â””â”€â”€ README.md



---

## Methods Used

### Preprocessing & EDA
- Dropped missing values and inconsistent rows.
- Standardized continuous variables (`Age`, `BMI`, `Avg_Glucose`).
- One-hot encoded categorical variables (`Gender`, `SES`, `Smoking_Status`).
- EDA outputs:
  - **fig1.pdf**: feature distributions.
  - **fig2.pdf**: correlation heatmap & target associations.

### Data Splitting & Scaling
- **Stratified split**: 70% train, 15% validation, 15% test.  
- **StandardScaler** fit only on train set, applied to val/test.  
- Validation used for **early stopping** (when supported).  

### Models
Evaluated **14 supervised models**, including:
- Logistic Regression (L1, L2)
- Decision Tree, Random Forest
- Gradient Boosting, XGBoost, LightGBM, CatBoost
- SVM (linear, RBF)
- KNN, Naive Bayes
- Ensemble methods (Voting, Bagging, Boosting)

### Hyperparameter Tuning
- Used **GridSearchCV** and **Optuna** (5-fold time-aware CV).
- Optimized depth, learning rate, regularization, number of estimators, and class weights.

### Evaluation & Selection
- Metrics: **Accuracy, Precision, Recall, F1, ROC-AUC, PR-AUC**.
- Figures:
  - **fig3.pdf**: model comparison & ranking.
  - **fig4.pdf**: confusion matrices, ROC & PR curves.

### Statistical Validation
- Applied **significance tests** (paired t-test, McNemarâ€™s test) to compare classifiers.
- Highlighted differences in recall/precision for minority class (stroke cases).

### Ensemble Methods
- Implemented **Soft Voting Classifier** combining best 3 models.
- Ensemble improved overall AUC and recall compared to individual models.
- **fig5.pdf**: ensemble performance.

---
## Setup

### 1) (Optional) Create a virtual environment
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# macOS / Linux
source venv/bin/activate

2) Install dependencies

If you have requirements.txt:
pip install -r requirements.txt
Otherwise:
pip install numpy pandas matplotlib seaborn scikit-learn xgboost lightgbm catboost optuna reportlab pypdf

3) Dataset

Place stroke_data.csv inside the data/ folder.

---
â–¶ï¸ How to Run

Run the full pipeline:
python main.py

This will:

Preprocess data and run EDA (fig1.pdf, fig2.pdf)

Train & tune 14 supervised models

Generate evaluation reports (fig3.pdf, fig4.pdf)

Train ensemble model and save results (fig5.pdf)

Export final PDF report to results/

ğŸ“ Outputs

fig1.pdf â€” Feature distributions (EDA)

fig2.pdf â€” Correlation heatmap

fig3.pdf â€” Model comparison & selection

fig4.pdf â€” Confusion matrices, ROC & PR curves

fig5.pdf â€” Ensemble results & statistical tests

final_report.pdf â€” Complete project report

âœ… Key Results (current run)

Best Individual Model: Logistic Regression (L1)

Accuracy: 0.842

ROC-AUC: 0.856

Recall (Stroke class): 0.781

Best Ensemble: Soft Voting (LR + Random Forest + CatBoost)

Accuracy: 0.849

ROC-AUC: 0.869

Recall (Stroke class): 0.804

ğŸ” Reproducibility

random_state=42 everywhere

Stratified splits for balanced folds

Scaling applied only after splitting

ğŸ§© Files â€” What They Do

preprocessing.py â€” cleaning, encoding, scaling

eda_analysis.py â€” EDA plots & feature correlations

model_training.py â€” model wrappers & training functions

hyperparameter_tuning.py â€” GridSearchCV & Optuna optimization

evaluation.py â€” metrics, curves, confusion matrices

ensemble_methods.py â€” voting, bagging, boosting

pdf_saver.py â€” saves figures as PDFs

main.py â€” orchestrates entire pipeline

ğŸ”— Data & Code

Dataset: Kaggle Stroke Diagnosis and Health Metrics

This repo includes all scripts to reproduce the analysis and figures.

Author

Hoshen Maimon

Contact

Questions or feedback: hoshenmn@gmail.com

License

Academic / coursework use. For other uses, please contact the author(s).

